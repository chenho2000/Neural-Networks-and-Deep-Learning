{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSC421 Assignment 2: Convolutional Networks\n",
    "\n",
    "**Deadline**: March 5, 2021 by 10pm\n",
    "\n",
    "**Submission**: Submit a PDF report containing your code, outputs,\n",
    "and your written solutions.\n",
    "You may export the completed notebook, but if you do so\n",
    "**it is your responsibly to make sure that your code and answers do not get cut off**.\n",
    "\n",
    "**Late Submission**: Please see the syllabus for the late submission criteria.\n",
    "\n",
    "**Working with a partner**: You may work with a partner for this assignment.\n",
    "If you decide to work with a partner, please create your group on Markus by\n",
    "February 5, 10pm, even if you intend to use grace tokens. Markus does not allow\n",
    "you to create groups past the deadline, even if you have grace tokens remaining.\n",
    "\n",
    "\n",
    "In this assignment, we will build a convolutional neural network that can predict \n",
    "whether two shoes are from the **same pair** or from two **different pairs**.\n",
    "This kind of application can have real-world applications: for example to help\n",
    "people who are visually impaired to have more independence.\n",
    "\n",
    "We will explore two convolutional architectures. While we will give you a tiny\n",
    "big of starter code to help make data processing a bit easier,\n",
    "you'll have a chance to build your neural network all by yourself!\n",
    "\n",
    "You may modify the starter code as you see fit, including changing the signatures of\n",
    "functions and adding/removing helper functions. However, please make sure that your\n",
    "TA can understand what you are doing and why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1. Data\n",
    "\n",
    "We will be releasing the combined assignment 2 data set from the entire\n",
    "class on Quercus. There will be an announcement with the data set is posted.\n",
    "You can complete coding Q1 even before the data set is released. In fact,\n",
    "we recommend testing your code with just your own set of shoes, so the code\n",
    "runs faster!\n",
    "\n",
    "\n",
    "There will be three main folders in the file:\n",
    "`train`, `test_w` and `test_m`. Data in `train` will be used for\n",
    "training and validation, and the data in the other folders will be used for testing.\n",
    "This is so that the entire class will have the same test sets.\n",
    "\n",
    "We've separated `test_w` and `test_m` so that we can track our model performance \n",
    "for women's shoes and men's shoes separately. Each of the test sets contain images\n",
    "from 10 students who submitted images of either exclusively men's shoes or women's shoes.\n",
    "\n",
    "If you are using Google Colab, upload this data to Google Colab.\n",
    "Then, mount Google Drive from your Google Colab notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you have done so, read this entire section (ideally this entire handout)\n",
    "before proceeding. There are right and wrong ways of\n",
    "processing this data. If you don't make the correct choices, you may find\n",
    "yourself needing to start over.\n",
    "Many machine learning projects fail because of the lack of care taken during\n",
    "the data processing stage.\n",
    "\n",
    "### Part (a) -- 1 pts\n",
    "\n",
    "Why might we care about the accuracies of the men's and women's shoes as two\n",
    "separate measures? Why would we expect our model accuracies for the two groups\n",
    "to be different?\n",
    "\n",
    "Recall that your application may help people who are visually impaired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer goes here. Please make sure it is not cut off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (b) -- 4 pts\n",
    "\n",
    "Load the training and test data, and separate your training data into training and validation.\n",
    "Create the numpy arrays `train_data`, `valid_data`, `test_w` and `test_m`, all of which should\n",
    "be of shape `[*, 3, 2, 224, 224, 3]`. The dimensions of these numpy arrays are as follows:\n",
    "\n",
    "- `*` - the number of students allocated to train, valid, or test\n",
    "- `3` - the 3 pairs of shoes submitted by that student\n",
    "- `2` - the left/right shoes\n",
    "- `224` - the height of each image\n",
    "- `224` - the width of each image\n",
    "- `3` - the colour channels\n",
    "\n",
    "So, the item `train_data[4,0,0,:,:,:]` should give us the left shoe of the first image submitted\n",
    "by the 5th student.The item `train_data[4,0,1,:,:,:]`  should be the right shoe in the same pair. \n",
    "The item `train_data[4,1,1,:,:,:]`  should be the right shoe in a different pair, submitted by\n",
    "the same student.\n",
    "\n",
    "When you first load the images using (for example) `plt.imread`, you may see a numpy array of shape\n",
    "`[224, 224, 4]` instead of `[224, 224, 3]`. That last channel is the alpha channel for transparent\n",
    "pixels, and should be removed. \n",
    "The pixel intensities are stored as an integer between 0 and 255.\n",
    "Divide the intensities by 255 so that you have floating-point values between 0 and 1. Then, subtract 0.5\n",
    "so that the elements of `train_data`, `valid_data` and `test_data` are between -0.5 and 0.5.\n",
    "**Note that this step actually makes a huge difference in training! (why??)**\n",
    "\n",
    "This function might take a while to run---it might take 3-4 minutes just to load the files from Google Drive.\n",
    "If you want to avoid running this code multiple times, you can save your numpy arrays and load it later:\n",
    "https://docs.scipy.org/doc/numpy/reference/generated/numpy.save.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here. Make sure it does not get cut off\n",
    "# You can use the code below to help you get started. You're welcome to modify\n",
    "# the code or remove it entirely: it's just here so that you don't get stuck\n",
    "# reading files\n",
    "\n",
    "import glob\n",
    "path = \"/content/gdrive/My Drive/CSC321/data/train/*.jpg\" # edit me\n",
    "images = {}\n",
    "for file in glob.glob(path):\n",
    "    filename = file.split(\"/\")[-1]   # get the name of the .jpg file\n",
    "    img = plt.imread(file)           # read the image as a numpy array\n",
    "    images[filename] = img[:, :, :3] # remove the alpha channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code, include the image in your PDF submission\n",
    "# plt.figure()\n",
    "# plt.imshow(train_data[4,0,0,:,:,:]) # left shoe of first pair submitted by 5th student\n",
    "# plt.figure()\n",
    "# plt.imshow(train_data[4,0,1,:,:,:]) # right shoe of first pair submitted by 5th student\n",
    "# plt.figure()\n",
    "# plt.imshow(train_data[4,1,1,:,:,:]) # right shoe of second pair submitted by 5th student"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (c) -- 2 pts\n",
    "\n",
    "Since we want to train a model that determines whether two shoes come from the **same**\n",
    "pair or **different** pairs, we need to create some labelled training data.\n",
    "Our model will take as input an image, either consisting of two shoes from the **same pair**\n",
    "or from **different pairs**. So, we'll need to generate some *positive examples* with\n",
    "images containing two shoes that *are* from the same pair, and some *negative examples* where \n",
    "images containing two shoes that *are not* from the same pair.\n",
    "We'll generate the *positive examples* in this part, and the *negative examples* in part (c).\n",
    "\n",
    "Write a function `generate_same_pair()` that takes one of the data sets that you produced\n",
    "in part (a), and generates a numpy array where each pair of shoes in the data set is\n",
    "concatenated together. In particular, we'll be concatenating together images of left\n",
    "and right shoes along the **height** axis. Your function `generate_same_pair` should\n",
    "return a  numpy array of shape `[*, 448, 224, 3]`.\n",
    "\n",
    "(Later on, we will need to convert this numpy array into a PyTorch tensor with shape\n",
    "`[*, 3, 448, 224]`. For now, we'll keep the RGB channel as the last dimension since\n",
    "that's what `plt.imshow` requires)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here\n",
    "\n",
    "# Run this code, include the result with your PDF submission\n",
    "print(train_data.shape) # if this is [N, 3, 2, 224, 224, 3]\n",
    "print(generate_same_pair(train_data).shape) # should be [N*3, 448, 224, 3]\n",
    "plt.imshow(generate_same_pair(train_data)[0]) # should show 2 shoes from the same pair"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (d) -- 2 pts\n",
    "\n",
    "Write a function `generate_different_pair()` that takes one of the data sets that\n",
    "you produced in part (a), and generates a numpy array in the same shape as part (b).\n",
    "However, each image will contain 2 shoes from a **different** pair, but submitted\n",
    "by the **same student**. Do this by jumbling the 3 pairs of shoes submitted by \n",
    "each student.\n",
    "\n",
    "Theoretically, for each student image submissions, there are 6 different combinations\n",
    "of \"wrong pairs\" that we could produce. To keep our data set *balanced*, we will\n",
    "only produce **three** combinations of wrong pairs per unique person.\n",
    "In other words,`generate_same_pairs` and `generate_different_pairs` should\n",
    "return the same number of training examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here\n",
    "\n",
    "# Run this code, include the result with your PDF submission\n",
    "print(train_data.shape) # if this is [N, 3, 2, 224, 224, 3]\n",
    "print(generate_different_pair(train_data).shape) # should be [N*3, 448, 224, 3]\n",
    "plt.imshow(generate_different_pair(train_data)[0]) # should show 2 shoes from different pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (e) -- 1 pts\n",
    "\n",
    "Why do we insist that the different pairs of shoes still come from the same\n",
    "student?  (Hint: what else do images from the same student have in common?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer goes here. Please make sure it is not cut off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (f) -- 1 pts\n",
    "\n",
    "Why is it important that our data set be *balanced*? In other words suppose we created\n",
    "a data set where 99% of the images are of shoes that are *not* from the same pair, and \n",
    "1% of the images are shoes that *are* from the same pair. Why could this be a problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer goes here. Please make sure it is not cut off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2. 1D Convolutions\n",
    "\n",
    "In our treatment of convolutional neural networks,\n",
    "we focused on CNNs for images, which has a 2D geometry.\n",
    "Other types of data like audio, text, and time series data have a 1D geometry,\n",
    "and we can use convolutions for those data sets as well.\n",
    "For audio data, you can think of convolutions\n",
    "as detecting features in a small region in time.\n",
    "\n",
    "1D convolutions are simpler numerically, so it is worth\n",
    "looking at the math and computation behind 1D convolutions\n",
    "before we analyze 2D convolutions.\n",
    "\n",
    "Suppose we have audio or time series data that looks like this,\n",
    "where the target $t$ is binary:\n",
    "\n",
    "| x | t  |\n",
    "|------------------------------|-----|\n",
    "| [1, 2, 3, 1, 0, -1, 3] | 1 |\n",
    "| [0, 1, 4, 3, 1, 1, 1] | 1 |\n",
    "| [1, 3, 2, 1, 1, 0, 1] | 0 |\n",
    "\n",
    "A 1D convolution can be applied by taking a 1D kernel (say [-1, 2, -1]),\n",
    "and sliding it across the sequence.\n",
    "At each position, we compute the dot product between the input with the kernel,\n",
    "like this:\n",
    "\n",
    "![](1dconv.png){ width=2in }\n",
    "\n",
    "(Image might not show up in the .ipynb file. If so, please check the\n",
    "PDF version of the handout.)\n",
    "\n",
    "### Part (a) -- 2 pts\n",
    "\n",
    "Suppose we are building a neural network to classify time series data like the one\n",
    "above. The architecture we choose will look like this:\n",
    "\n",
    "- In the first layer, we'll apply a 1D convolution with kernel size 3. The number of\n",
    "  input channels is 1, and the number of output channels is also 1. We won't use any\n",
    "  zero padding.\n",
    "  We'll initialize the weights of this 1D convolution to ${\\bf w}^{(1)} = [-1, 2, -1]$\n",
    "  like in the figure, and initialize the bias to ${\\bf b}^{(1)} = 0$.\n",
    "  We will apply the ReLU activation after this layer.\n",
    "- In the second layer, we'll have a fully-connected layer. There are 5 input units,\n",
    "  and a single output unit. We'll initialize all the weights and biase to 1 so \n",
    "  $w_k^{(2)} = 1$ and $b^{(2)} = 1$.\n",
    "- We'll use the cross-entropy loss.\n",
    "\n",
    "Compute the forward pass for the data point $x = [1, 3, 2, 1, 1, 0, 1]$, $t = 0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer goes here. Make sure to show your work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (b) -- 3 pts\n",
    "\n",
    "Use backpropagation to compute the error signal $\\overline{{\\bf w}^{(1)}}$ of the\n",
    "1D convolution kernel for the same single data point $x = [1, 3, 2, 1, 1, 0, 1]$, $t = 0$.\n",
    "Show your steps.\n",
    "You do not need to compute the error signal for the other parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer goes here. Make sure to show your work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (c) -- 3 pts\n",
    "\n",
    "1D convolutions can be and have been used for language modeling, where the sequence\n",
    "${\\bf x}$ represents a sequence of *words* in a sentence. Our target can\n",
    "represent (for example) whether a sentence conveys positive or negative\n",
    "sentiment.\n",
    "\n",
    "The way we typically represent each *word* is either using a one-hot embedding\n",
    "(like in Assignment 1) or using distributed representations (like the one we learned\n",
    "in Assignment 1). In either case, each word will be represented using a vector. Here\n",
    "is a representation of a sentence ${\\bf x} = w_1, w_2, \\cdots, w_T$ using one-hot\n",
    "vectors:\n",
    "\n",
    "| $w_1$ | $w_2$ | $w_3$ | $\\cdots$  | $w_T$ |\n",
    "|------|-----|-----|-----|-----|\n",
    "| 0 | 0 | 0 | $\\cdots$ | 1 |\n",
    "| 1 | 0 | 0 | $\\cdots$ | 0 |\n",
    "| 0 | 0 | 0 | $\\cdots$ | 0 |\n",
    "| 0 | 1 | 0 | $\\cdots$ | 0 |\n",
    "| $\\vdots$ | $\\vdots$ | $\\vdots$ | $\\vdots$ | $\\vdots$ |\n",
    "| 0 | 0 | 0 | $\\cdots$ | 0 |\n",
    "\n",
    "In particular, we can represent ${\\bf x}$ as a matrix of shape $V \\times T$, where $V$\n",
    "is the size of the vocabulary and $T$ is the length of the sentence. This representation\n",
    "of ${\\bf x}$ looks like a 2D, greyscale image!\n",
    "\n",
    "Explain why it is *not* actually reasonable to use a 2D convolutional kernel\n",
    "(e.g., a 3x3 kernel like earlier) on this data.  (1.5pt)\n",
    "\n",
    "What kind of computation should we use instead so that\n",
    "a 1D convolution can take account of the fact that each word $w_j$ is a\n",
    "$V$-dimensional vector? (1.5 pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer goes here. Make sure to show your work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (d) -- 2 pts\n",
    "\n",
    "In this problem we will look at the \\textit{effective receptive field} that results from a sequence of 1D convolutions.\n",
    "Consider a 1D convolution with kernel width $K$.\n",
    "The diagram below illustrates how the effective receptive field grows as we perform a chain of convolutions.\n",
    "\n",
    "![](CSC413_1D_Conv.png){ width=200px }\n",
    "\n",
    "Let the kernel width be $K$ (i.e., $K=3$ in the diagram above, but we will consider arbitrary $K$).\n",
    "\n",
    "What is the width of the effective receptive field of a unit in the $N^{th}$ layer?\n",
    "\n",
    "Your answer should be expressed as a closed-form equation involving the variables $K$ and $N$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer goes here. Make sure to show your work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3. CNN Implementation\n",
    "\n",
    "Before starting this question, we recommend reviewing the lecture materials\n",
    "on convolutional neural networks, including the demo from lecture 5.\n",
    "\n",
    "In this section, we will build two CNN models in PyTorch.\n",
    "\n",
    "### Part (a) -- 3 pts\n",
    "\n",
    "Implement a CNN model in PyTorch called `CNN` that will take images of size\n",
    "$3 \\times 448 \\times 224$, and classify whether the images contain shoes from\n",
    "the same pair or from different pairs.\n",
    "\n",
    "The model should contain the following layers:\n",
    "\n",
    "- A convolution layer that takes in 3 channels, and outputs $n$ channels.\n",
    "- A $2 \\times 2$ downsampling (either using a strided convolution in the previous step, or max pooling)\n",
    "- A second convolution layer that takes in $n$ channels, and outputs $n \\times 2$ channels.\n",
    "- A $2 \\times 2$ downsampling (either using a strided convolution in the previous step, or max pooling)\n",
    "- A third convolution layer that takes in $n \\times 2$ channels, and outputs $n \\times 4$ channels.\n",
    "- A $2 \\times 2$ downsampling (either using a strided convolution in the previous step, or max pooling)\n",
    "- A fourth convolution layer that takes in $n \\times 4$ channels, and outputs $n \\times 8$ channels.\n",
    "- A $2 \\times 2$ downsampling (either using a strided convolution in the previous step, or max pooling)\n",
    "- A fully-connected layer with 100 hidden units\n",
    "- A fully-connected layer with 2 hidden units\n",
    "\n",
    "Make the variable $n$ a parameter of your CNN. You can use either $3 \\times 3$ or $5 \\times 5$\n",
    "convolutions kernels. Set your padding to be `(kernel_size - 1) / 2` so that your feature maps\n",
    "have an even height/width.\n",
    "\n",
    "Note that we are omitting certain steps that practitioners will typically not mention,\n",
    "like ReLU activations and reshaping operations. Use the lecture, tutorial, and assignment\n",
    "materials to figure out where they are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, n=4):\n",
    "        super(CNN, self).__init__()\n",
    "        # TODO: complete this method\n",
    "\n",
    "    # TODO: complete this class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (b) -- 3 pts\n",
    "\n",
    "Implement a CNN model in PyTorch called `CNNChannel` that contains the same layers as\n",
    "in the Part (a), but with one crucial difference: instead of starting with an image\n",
    "of shape $3 \\times 448 \\times 224$, we will first manipulate the image so that the\n",
    "left and right shoes images are concatenated along the **channel** dimension.\n",
    "\n",
    "![](https://www.cs.toronto.edu/~lczhang/321/hw/p3model.png){ width=400px }\n",
    "<img src=\"https://www.cs.toronto.edu/~lczhang/321/hw/p3model.png\" width=\"400px\" />\n",
    "\n",
    "Complete the manipulation in the `forward()` method (by slicing and using\n",
    "the function `torch.cat`). The input to the first convolutional layer\n",
    "should have 6 channels instead of 3 (input shape $6 \\times 224 \\times 224$).\n",
    "\n",
    "Use the same hyperparameter choices as you did in part (a), e.g. for the kernel size,\n",
    "choice of downsampling, and other choices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNChannel(nn.Module):\n",
    "    def __init__(self, n=4):\n",
    "        super(CNNChannel, self).__init__()\n",
    "        # TODO: complete this method\n",
    "\n",
    "    # TODO: complete this class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part (c) -- 2 pts\n",
    "\n",
    "Although our task is a binary classification problem, we will still use the architecture\n",
    "of a multi-class classification problem. That is, we'll use a one-hot vector to represent\n",
    "our target (just like in Assignment 1). We'll also use `CrossEntropyLoss` instead of\n",
    "`BCEWithLogitsLoss`. In fact, this is a standard practice in machine learning because\n",
    "this architecture performs better!\n",
    "\n",
    "Explain why this architecture will generally give us better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer goes here. Please make sure it is not cut off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (d) -- 3 pts\n",
    "\n",
    "Compute the number of parameters in your `CNN` and `CNNChannel` models.\n",
    "You should do this computation step-by-step manually, rather than trying to find\n",
    "a PyTorch function to do it for you. This value should be a function of $n$ \n",
    "and the kernel size $k$ that you chose (either 3 or 5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer goes here. Show your work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part (e) -- 2 pts\n",
    "\n",
    "From part (d), you should see that the two models have roughly the same number\n",
    "of parameters.  However, one of these models will perform better,\n",
    "showing that architecture choices **do** matter in machine learning.\n",
    "Explain why one of these models performs better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer goes here. Please make sure it is not cut off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part (f) -- 4 pts\n",
    "\n",
    "For this question, let's consider the `CNNChannel` model.\n",
    "Consider a hidden unit directly **after** the first downsampling operation.\n",
    "What is the *receptive field* of a unit close to the center of the feature map?\n",
    "In other words, how many pixels (from one shoe image) affect the activation\n",
    "value of that unit? (Note: we're studying units from the center of the\n",
    "feature map/image so you don't have to worry about hitting the image boundary.)\n",
    "\n",
    "Repeat the same computation for the hidden unit directly after the second,\n",
    "third, and fourth downsampling operation.\n",
    "\n",
    "Notice that your answer here is very different from your answer from Q2(d).\n",
    "The key difference is the **downsampling** operations that we are performing.\n",
    "Because of these downsampling operations, later\n",
    "layers can detect features from a large portion of the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer goes here. Make sure to show your work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part (g) -- 2 pts\n",
    "\n",
    "The function `get_accuracy` is written for you. You may need to modify this\n",
    "function depending on how you set up your model and training.\n",
    "\n",
    "Unlike in assignment 1, we will separately compute the model accuracy on the\n",
    "positive and negative samples.  Explain why we may wish to track these\n",
    "two values separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer goes here. Please make sure it is not cut off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(model, data, batch_size=50):\n",
    "    \"\"\"Compute the model accuracy on the data set. This function returns two\n",
    "    separate values: the model accuracy on the positive samples,\n",
    "    and the model accuracy on the negative samples.\n",
    "\n",
    "    Example Usage:\n",
    "\n",
    "    >>> model = CNN() # create untrained model\n",
    "    >>> pos_acc, neg_acc= get_accuracy(model, valid_data)\n",
    "    >>> false_positive = 1 - pos_acc\n",
    "    >>> false_negative = 1 - neg_acc\n",
    "    \"\"\"\n",
    "\n",
    "    model.eval()\n",
    "    n = data.shape[0]\n",
    "\n",
    "    data_pos = generate_same_pair(data)      # should have shape [n * 3, 448, 224, 3]\n",
    "    data_neg = generate_different_pair(data) # should have shape [n * 3, 448, 224, 3]\n",
    "\n",
    "    pos_correct = 0\n",
    "    for i in range(0, len(data_pos), batch_size):\n",
    "        xs = torch.Tensor(data_pos[i:i+batch_size]).transpose(1, 3)\n",
    "        zs = model(xs)\n",
    "        pred = zs.max(1, keepdim=True)[1] # get the index of the max logit\n",
    "        pred = pred.detach().numpy()\n",
    "        pos_correct += (pred == 1).sum()\n",
    "    \n",
    "    neg_correct = 0\n",
    "    for i in range(0, len(data_neg), batch_size):\n",
    "        xs = torch.Tensor(data_neg[i:i+batch_size]).transpose(1, 3)\n",
    "        zs = model(xs)\n",
    "        pred = zs.max(1, keepdim=True)[1] # get the index of the max logit\n",
    "        pred = pred.detach().numpy()\n",
    "        neg_correct += (pred == 0).sum()\n",
    "\n",
    "    return pos_correct / (n * 3), neg_correct / (n * 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4. Training\n",
    "\n",
    "Now, we will write the functions required to train the model.\n",
    "\n",
    "### Part (a) -- 8 pts\n",
    "\n",
    "Write the function `train_model` that takes in (as parameters) the model, training data,\n",
    "validation data, and other hyperparameters like the batch size, weight decay, etc.\n",
    "This function should be somewhat similar to the training code that you wrote\n",
    "in assignment 1, but with a major difference in the way we treat our training data.\n",
    "\n",
    "Since our positive and negative training sets are separate, it is actually easier for\n",
    "us to generate separate minibatches of positive and negative training data! In\n",
    "each iteration, we'll take `batch_size / 2` positive samples and `batch_size / 2`\n",
    "negative samples. We will also generate labels of 1's for the positive samples,\n",
    "and 0's for the negative samples.\n",
    "\n",
    "Here's what we will be looking for:\n",
    "\n",
    "- main training loop; choice of loss function; choice of optimizer\n",
    "- obtaining the positive and negative samples\n",
    "- shuffling the positive and negative samples at the start of each epoch\n",
    "- in each iteration, take `batch_size / 2` positive samples and `batch_size / 2` negative samples\n",
    "  as our input for this batch\n",
    "- in each iteration, take `np.ones(batch_size / 2)` as the labels for the positive samples, and \n",
    "  `np.zeros(batch_size / 2)` as the labels for the negative samples\n",
    "- conversion from numpy arrays to PyTorch tensors, making sure that the input has dimensions \"NCHW\",\n",
    "  use the `.transpose()` method in either PyTorch or numpy\n",
    "- computing the forward and backward passes\n",
    "- after every epoch, checkpoint your model (A1 had in-depth instructions and examples for how to do this)\n",
    "- after every epoch, report the accuracies for the training set and validation set\n",
    "- track the training curve information and plot the training curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (b) -- 2 pts\n",
    "\n",
    "Sanity check your code from Q3(a) and from Q2(a) and Q2(b) by showing that your models\n",
    "can \"memorize\" a very small subset of the training set (e.g. 5 images). That is,\n",
    "show that your model can achieve 90%+ accuracy relatively quickly (within ~50 or so iterations)\n",
    "on a training set size of ~5 images.\n",
    "\n",
    "This question is really here to make sure that your model/training code is correct.\n",
    "The question itself is not worth much, but your results here will diagnose issues\n",
    "from other parts of your code.\n",
    "\n",
    "(If you have trouble with CNN() but not CNNChannel(), try reducing $n$, e.g. try working\n",
    "with the model `CNN(2)`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here. Remember to include your results so that your TA can\n",
    "# see that your model attains a high training accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (c) -- 4 pts\n",
    "\n",
    "Train your models from Q2(a) and Q2(b). You will want to explore the effects of a few \n",
    "hyperparameters, including the learning rate, batch size, choice of $n$, and potentially\n",
    "the kernel size. You do not need to check all values for all hyperparameters. Instead,\n",
    "get an intuition about what each of the parameters do.\n",
    "\n",
    "In this section, explain how you tuned your hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include the training curves for the two models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (d) -- 2 pts\n",
    "\n",
    "Include your training curves for the **best** models from each of Q2(a) and Q2(b).\n",
    "These are the models that you will use in the next question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include the training curves for the two models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5. Test Accuracy\n",
    "\n",
    "### Part (a) -- 3 pts\n",
    "\n",
    "Report the test accuracies of your **single best** model,\n",
    "separately for the two test sets.\n",
    "Do this by choosing the checkpoint of the model\n",
    "architecture that produces the best validation accuracy. That is,\n",
    "if your model attained the\n",
    "best validation accuracy in epoch 12, then the weights at epoch 12 is what you should be using\n",
    "to report the test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here. Make sure to include the test accuracy in your report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (b) -- 1 pts\n",
    "\n",
    "Display one set of men's shoes that your model correctly classified as being\n",
    "from the same pair.\n",
    "\n",
    "If your test accuracy was not 100% on the men's shoes test set,\n",
    "display one set of inputs that your model classified incorrectly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure both your code and image are visible to the TA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (c) -- 1 pts\n",
    "\n",
    "Display one set of women's shoes that your model correctly classified as being\n",
    "from the same pair.\n",
    "\n",
    "If your test accuracy was not 100% on the women's shoes test set,\n",
    "display one set of inputs that your model classified incorrectly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure both your code and image are visible to the TA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6. Graph Neural Networks\n",
    "\n",
    "In this question, we will introduce a relatively new type of neural network\n",
    "that generalizes convolutions, namely Graph Neural Networks (GNNs).\n",
    "\n",
    "Recall that a *graph* is a pair $G = (V, E)$ consisting of a set of *vertices*\n",
    "(also called *nodes*) $V$ and a set of *edges* $E$.\n",
    "Each edge is a pair of vertices, denoting a connection between them in the graph.\n",
    "For example, the graph below is represented by the sets\n",
    "$V = \\{ v_1, v_2, v_3, v_4 \\}$ and $E = \\{ (v_1, v_2), (v_2, v_3), (v_2, v_4), (v_3, v_4) \\}$.\n",
    "We will only consider undirected graphs for this question,\n",
    "so the ordering of the nodes in each edge is not important.\n",
    "\n",
    "![](CSC413_ExampleGraph.png){ width=200px }\n",
    "\n",
    "(Image might not show up in the .ipynb file. If so, please check the\n",
    "PDF version of the handout.)\n",
    "\n",
    "\n",
    "Many different types of structured data can be represented by graphs.\n",
    "In particular, an image can be represented by a grid-structured graph!\n",
    "Each node represents a pixel, and edges represent adjacency between pixels in space.\n",
    "\n",
    "Graph Neural Networks (GNNs) generalize convolutions for arbitrary graph-structured data.\n",
    "Each node is associated with a vector representation (like the RGB representation of a pixel).\n",
    "A \"layer\" in a GNN updates the representation of each node $v$ by taking a linear\n",
    "combination of the representations of its neighbours $u \\in N(v)$\n",
    "(just like how a 3x3 convolution updates a pixel's representation by taking\n",
    "a linear combinations of the pixel's 8 direct neighbours, plus the pixel itself!).\n",
    "\n",
    "If we denote the representation at node $v$ after the $\\ell^{th}$ layer by\n",
    "$\\mathbf{h}_v^{(l)}$, then its representation after a GNN update is:\n",
    "\n",
    "$$\\mathbf{h}_v^{(l+1)} = f\\left( \\sum_{u \\in N(v) \\cup \\{ v \\}} \\mathbf{W}^{(l+1)} \\mathbf{h}^{(l)}_u \\right)$$\n",
    "\n",
    "Here, $f$ is a nonlinearity such as ReLU, and $\\mathbf{W}^{(l+1)}$ are the\n",
    "parameters of the $(l+1)^{th}$ layer of the GNN.\n",
    "\n",
    "After $k$ GNN layers, each node's representation is affected by other nodes\n",
    "within a $k$-hop radius (this is similar to the receptive field analysis\n",
    "from earlier).\n",
    "Deeper models are able to extract higher-level representations for each node by\n",
    "aggregating information from larger neighbourhoods.\n",
    "\n",
    "There are two main types of prediction tasks we may want to perform on graphs:\n",
    "*node-level* (is this pixel a part of a cat?) and *graph-level* (is this molecule,\n",
    "represented by this entire graph, be useful for treating a disease?).\n",
    "We can obtain a representation of an entire graph by \n",
    "aggregating the final representations of each node in the graph.\n",
    "\n",
    "For the rest of this question, we'll assume that we want to make a prediction about\n",
    "the entire graph. Our GNN will compute a single scalar for the graph:\n",
    "\n",
    "$$\n",
    "y = \\sigma \\left( \\mathbf{q}^\\top \\left( \\sum_{v \\in V} \\mathbf{h}_v \\right) \\right)\n",
    "$$\n",
    "where $\\mathbf{q}$ is a vector of the same dimensionality as $\\mathbf{h}$ (so that the inner product is a scalar) and the activation $\\sigma$ is the logistic sigmoid.\n",
    "\n",
    "\n",
    "### Part (a) -- 2 pts\n",
    "\n",
    "In this question, we will be applying graph convolutions by hand in the simple graph\n",
    "from above. The figure below shows the initial vector representation of each vertex.\n",
    "(Think of these vectors $h_k^{0}$ as similar to the vector of RGB values at each pixel\n",
    "in the earlier parts of this assignment.)\n",
    "\n",
    "![](CSC413_ExerciseGraph.png){ width=300px }\n",
    "\n",
    "(Image might not show up in the .ipynb file. If so, please check the\n",
    "PDF version of the handout.)\n",
    "\n",
    "Suppose that the parameters of the GNN are as follows:\n",
    "$$\n",
    "\\mathbf{W} =\n",
    "\\begin{bmatrix}\n",
    "1 & 2 \\\\\n",
    "0 & 1\n",
    "\\end{bmatrix}\n",
    "% \\qquad \\qquad\n",
    "% V =\n",
    "% \\begin{bmatrix}\n",
    "% 1 & 1 \\\\\n",
    "% 1 & 1\n",
    "% \\end{bmatrix}\n",
    "\\qquad \\qquad\n",
    "\\mathbf{q} = \n",
    "\\begin{bmatrix}\n",
    "1 & 1\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Compute 1 convolutional update step in this graph. \n",
    "In other words, find the updated representations for each node after\n",
    "1 propagation step and report the values $\\mathbf{h}^{(1)}_1$,\n",
    "$\\mathbf{h}^{(1)}_2$, $\\mathbf{h}^{(1)}_3$, $\\mathbf{h}^{(1)}_4$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer goes here. Make sure to show your work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (b) -- 2 pts\n",
    "\n",
    "Compute the graph-level output based on the representations you computed in part 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer goes here. Make sure to show your work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (c) -- 4 pts\n",
    "\n",
    "Assume that the target for the graph-level output is $0$,\n",
    "and that we're using cross-entropy loss. Use backpropagation to compute the gradient of the parameters of the GNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer goes here. Make sure to show your work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7. Work Allocation -- 2 pts\n",
    "\n",
    "This question is to make sure that if you are working with a partner, that\n",
    "you and your partner contributed equally to the assignment.\n",
    "\n",
    "Please have each team member write down the times that you worked on the\n",
    "assignment, and your contribution to the assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer goes here"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}
